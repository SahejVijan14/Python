{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "1. (50 points) Box Office Mojo (http://boxofficemojo.com) is a website that tracks a variety of information on movies released each year (such as genre, studio, box office revenues, etc.). You will write Python scripts that collect data on all the movies for the year that the user specifies and that are listed on the site. As an example, information on movies that were released in 2015 is available at: http://www.boxofficemojo.com/yearly/chart/?yr=2015&p=.htm\n",
    "Collect the following information for each movie and save in a comma separated text file named movies.txt:\n",
    "i. Movie Name.\n",
    "ii. Movie ID. Note that this is not displayed on the webpage, but appears in the source code for the page. For example, for movie “Star Wars: The Force Awakens”, the Movie ID is “starwars7”.\n",
    "iii. Studio that produced the movie.\n",
    "iv. Total Gross Earnings\n",
    "v. Total number of Theaters that the movie was shown\n",
    "vi. Opening Gross Earnings\n",
    "vii. Opening number of Theaters that the movie was shown\n",
    "In addition answer the following questions:\n",
    "i. What is the average Total Gross Earnings in the specified year\n",
    "ii. Name the movie(s) that had the maximum number of theaters that they were shown in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm\n",
    "Step-1  Import beautifulsoup pakage, import request,urlopen, urllib.request, re, os \n",
    "Step-2  Ask user what year it is intrested in\n",
    "Step-3  Enter site url for web scraping\n",
    "Step-4  Define the count for movies, movies id, studio name, earnings and number of theaters\n",
    "Step-5  Apply condition to find the rank of a movie\n",
    "Step-6  Enter all the data collected from the site in a .txt file and and separate it using a ','\n",
    "Step-7  Condition to open page for year entered buy the user and find necessary information\n",
    "Step-8  Ask the year from the user and print the answer\n",
    "Step-9  End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "\n",
    "import re #import regular function\n",
    "import os #import operating system dependent funtotionality\n",
    "\n",
    "yearInst = \"What is the year that you are interested in getting data:\"\n",
    "constPageHrefIncluded = \"/yearly/chart/?page=\"\n",
    "constFileName = \"movies.txt\"\n",
    "constFileSavedNameInst = \"The data is stored in file movies.txt\"\n",
    "# define what the program asks the user, where and by what name the files gets saved in text file \n",
    "\n",
    "urlBoxOfficeMojoHome = \"http://www.boxofficemojo.com\"\n",
    "preUrlYear = \"http://www.boxofficemojo.com/yearly/chart/?yr=\"\n",
    "postUrlYear = \"&p=.htm\"\n",
    "# enter site url and exact page for web scraping\n",
    "_year = 0\n",
    "\n",
    "globalMoviesWithMaxTheatres = 0\n",
    "globalMaxMovieTheatreCount = 0\n",
    "globalIsAverageEarningMovieFound = False\n",
    "globalAverageTotalGrossEarningsForYear = \"\"\n",
    "#define count for movies with max theatres, theatre count, gross earnings for the year\n",
    "def removeChar(charToSub, a_strToStringChar):\n",
    "  return re.sub(charToSub, '', a_strToStringChar)\n",
    "\n",
    "\n",
    "def writeMoviesDataTable(a_strPageLink):\n",
    "  currentPageSource = BeautifulSoup(urlopen(a_strPageLink).read())\n",
    "#scrap page source of the page with the information for all the movies \n",
    "  allTablesList = currentPageSource.findAll('table')\n",
    "\n",
    "  tableDataList = []\n",
    "  currentTableIndex = 0\n",
    "#Add content of data base in dictionary  \n",
    "  isMovieTableFound = False\n",
    "  for currentTable in allTablesList:\n",
    "    tableDataList = currentTable.findAll('td')\n",
    "#use find.all to find what you are exactly looking for    \n",
    "    for currentTableData in tableDataList:\n",
    "      if currentTableData.get_text() == \"Rank\":\n",
    "        isMovieTableFound = True\n",
    "        break\n",
    "#condition to find the rank of the movie and close the loop\n",
    "    if isMovieTableFound:\n",
    "      break\n",
    "    else:\n",
    "      currentTableIndex += 1\n",
    "\n",
    "  if isMovieTableFound == False:\n",
    "      return\n",
    "#condition to increase count for every data content found      \n",
    "  movieTable = allTablesList[currentTableIndex]\n",
    "\n",
    "  tableRows = movieTable.findAll('tr')\n",
    "  currentRowIndex = 1\n",
    "  rowCount = len(tableRows)\n",
    "\n",
    "  while currentRowIndex < rowCount:\n",
    "    currentRow = tableRows[currentRowIndex]\n",
    "    columns = currentRow.findAll('td')\n",
    "    columnCount = len(columns)\n",
    "\n",
    "    if columnCount == 9 or columnCount == 8:\n",
    "      rank = columns[0].get_text()\n",
    "      title = columns[1]\n",
    "\n",
    "      studio = removeChar(',',columns[2].get_text())\n",
    "      totalGrossEarnings = removeChar(',',columns[3].get_text())\n",
    "\n",
    "      totalTheatres = removeChar(',',columns[4].get_text())\n",
    "# indentify that movie name, ID, studio name, gross earnings, number of total and opening theatres movie is shown all are separated by ',' in the text file\n",
    "      global globalMaxMovieTheatreCount\n",
    "      global globalMoviesWithMaxTheatres\n",
    "      global globalIsAverageEarningMovieFound\n",
    "      global globalAverageTotalGrossEarningsForYear\n",
    "\n",
    "      if totalTheatres.isdigit():\n",
    "        if int(totalTheatres) > globalMaxMovieTheatreCount:\n",
    "          globalMaxMovieTheatreCount = int(totalTheatres)\n",
    "          globalMoviesWithMaxTheatres = title.get_text()\n",
    "        elif int(totalTheatres) == globalMaxMovieTheatreCount:\n",
    "          globalMoviesWithMaxTheatres += \",\" + title.get_text()\n",
    "\n",
    "      openingEarnings = removeChar(',',columns[5].get_text())\n",
    "\n",
    "      openingTheatres = removeChar(',',columns[6].get_text())\n",
    "\n",
    "      movieId = title.find('a').get('href')\n",
    "      movieId = movieId.replace('.htm','')\n",
    "      movieId = movieId.replace('/movies/?id=','')\n",
    "\n",
    "      fileToWrite = open(constFileName, \"a\")\n",
    "      fileToWrite.write(title.get_text() +\",\" + movieId +\",\"+ studio +\",\" + totalGrossEarnings +\",\"+ totalTheatres +\",\"+ openingEarnings +\",\"+ openingTheatres + \"\\n\")\n",
    "    elif globalIsAverageEarningMovieFound == False and globalAverageTotalGrossEarningsForYear == \"\" and columnCount == 7 or columnCount == 6:\n",
    "      if columns[0].get_text() == \"Averages:\": \n",
    "        globalAverageTotalGrossEarningsForYear = columns[1].get_text()\n",
    "        globalIsAverageEarningMovieFound = True\n",
    "# indentify that movie name, ID, studio name, gross earnings, number of total and opening theatres movie are written in seperate columns\n",
    "    currentRowIndex += 1\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "  currentSelection = input(\"\\n\"+yearInst)\n",
    "  if currentSelection.isdigit():\n",
    "    _year = int(currentSelection)  \n",
    "  else:\n",
    "    continue\n",
    "\n",
    "  current_url = preUrlYear + str(_year) + postUrlYear\n",
    "# condition to open page for the year entered by the user\n",
    "  request = requests.get(current_url)\n",
    "\n",
    "  if request.status_code != 200:\n",
    "    print(\"Data \" + current_url+\" for year does not exist.\")\n",
    "    continue\n",
    "# condition to ask question for the year again if the entered year does not exsist on the web page\n",
    "  baseYearUrlToOpen = urlopen(current_url)\n",
    "  readSource = BeautifulSoup(baseYearUrlToOpen.read())\n",
    "\n",
    "  allPageList = []\n",
    "  allPageSet = []\n",
    "\n",
    "  allLinks = readSource.findAll('a')\n",
    "#create a dictionary of page list and use find.all for finding exact data we nwwd\n",
    "\n",
    "  for hrefTag in allLinks:\n",
    "    if str(hrefTag.get('href')).find(constPageHrefIncluded) != -1:\n",
    "      allPageList.append(urlBoxOfficeMojoHome + str(hrefTag.get('href')))\n",
    "# use append to add data to the end of the list      \n",
    "  allPageList.append(current_url)\n",
    "  allPageSet = set(allPageList)\n",
    "\n",
    "  if len(allPageSet) == 0:\n",
    "    print(\"Data \" + current_url+\" for year does not exist.\")\n",
    "    continue\n",
    "\n",
    "  if os.path.exists(constFileName):\n",
    "    os.remove(constFileName)\n",
    "\n",
    "  globalAverageTotalGrossEarningsForYear = \"\"\n",
    "  globalMoviesWithMaxTheatres = \"\"\n",
    "  globalIsAverageEarningMovieFound = False\n",
    "  globalMaxMovieTheatreCount = 0\n",
    "\n",
    "  for l_currentPage in allPageSet:\n",
    "    writeMoviesDataTable(l_currentPage)\n",
    "  print(constFileSavedNameInst)\n",
    "\n",
    "\n",
    "  print(\"The average Total Gross Earnings for \"+str(_year)+\" is:\" + globalAverageTotalGrossEarningsForYear)\n",
    "\n",
    "  print(\"The movie(s) that were shown in the maximum number of theaters for \"+str(_year)+\" are:\" + globalMoviesWithMaxTheatres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "(50 points) The site Box Office Mojo (http://boxofficemojo.com) also has a People Index on movie actors (ordered by Total Gross) listed on the page: http://boxofficemojo.com/people/?view=Actor&pagenum=1&sort=sumgross&order=DESC&&p=.htm Collect the following information for each actor and save in a comma separated text file named actors.txt: i. Rank (Row number displayed on the page). ii. Actor Name. iii. Actor ID (it is in the source code of the webpage) iv. Total Gross v. Number of movies vi. # 1 picture In addition answer the following questions: i. Who is the actor(s) with the maximum number of movies ii. Who is the actor(s) with the highest average earnings per movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm\n",
    "Step-1 Import beautifulsoup pakage, import request,urlopen, urllib.request, re, os \n",
    "Step-2 Enter site url for web scraping\n",
    "Step-3 Add actor name, actor id, average earningins per movie, number of movies and highest earning movie in text file \n",
    "Step-4 Determine actor with most number of movies \n",
    "Step-5 Determine actor with highest average earnings per movie \n",
    "Step-6 End\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "\n",
    "import re\n",
    "import os\n",
    "#import regular impresions and operating system dependent funtotionality\n",
    "constActorsDataSotred = \"The data is stored in file actors.txt\"\n",
    "actorsHomeURL = \"http://www.boxofficemojo.com/people/?view=Actor&pagenum=1&sort=sumgross&order=DESC&&p=.htm\"\n",
    "\n",
    "constFileName = \"actors.txt\"\n",
    "\n",
    "urlBoxOfficeMojoHome = \"http://www.boxofficemojo.com\"\n",
    "\n",
    "urlPre = \"http://www.boxofficemojo.com/people/?view=Actor&pagenum=\"\n",
    "\n",
    "urlPost = \"&sort=sumgross&order=DESC&&p=.htm\"\n",
    "#enter url from where data needs to be scraped\n",
    "# create text file where data needs to be saved\n",
    "constPageHrefIncluded = \"/people/?view=Actor&pagenum=\"\n",
    "\n",
    "globalActorsWithMaxMovies= ''\n",
    "globalMaxMovieCount = 0\n",
    "globalMaxAvgEarnMovie = 0.0\n",
    "globalActorsWithMaxAvgPerMovie = ''\n",
    "globalRowIndex = 0\n",
    "# define count for actor with max movies, average earnings and max average per movie\n",
    "def removeChar(charToSub, a_strToStringChar):\n",
    "  return re.sub(charToSub, '', a_strToStringChar)\n",
    "\n",
    "def writeActorDataTable(a_strPageLink):\n",
    "\n",
    "  request = requests.get(a_strPageLink)\n",
    "  if request.status_code != 200:\n",
    "    print(\"Error while retrieving page \" + a_strPageLink)\n",
    "    return\n",
    "\n",
    "  urlSource = urlopen(a_strPageLink)\n",
    "  currentPageSource = BeautifulSoup(urlSource.read())\n",
    "  allTablesList = currentPageSource.findAll('table')\n",
    "  actorTable = []\n",
    "\n",
    "  tableDataList = []\n",
    "  currentTableIndex = 0\n",
    "  currentNestedTableIndex = 0\n",
    "  \n",
    "  isActorTableFound = False\n",
    "  for currentTable in allTablesList:\n",
    "    currentNestedTableList = currentTable.findAll('table')\n",
    "    for nestedTable in currentNestedTableList:\n",
    "      tableRowList = nestedTable.findAll('tr')\n",
    "      if len(tableRowList) >= 1:\n",
    "        tableDataList = tableRowList[0].findAll('td')\n",
    "        for currentTableData in tableDataList:\n",
    "          if currentTableData.get_text() == \"Row\":\n",
    "            actorTable = nestedTable\n",
    "            isActorTableFound = True\n",
    "            break\n",
    "      if isActorTableFound:\n",
    "        break\n",
    "    if isActorTableFound:\n",
    "        break\n",
    "\n",
    "  tableRows = actorTable.findAll('tr')\n",
    "  currentRowIndex = 1\n",
    "  rowCount = len(tableRows)\n",
    "\n",
    "  global globalActorsWithMaxMovies\n",
    "  global globalMaxMovieCount\n",
    "  global globalMaxAvgEarnMovie\n",
    "  global globalActorsWithMaxAvgPerMovie\n",
    "  global globalRowIndex\n",
    "\n",
    "  while currentRowIndex < rowCount:\n",
    "    currentRow = tableRows[currentRowIndex]\n",
    "    columns = currentRow.findAll('td')\n",
    "    columnCount = len(columns)\n",
    "\n",
    "    if columnCount == 7:\n",
    "      globalRowIndex += 1\n",
    "      rowNum = globalRowIndex\n",
    "      actorName = columns[1].get_text()\n",
    "#condition to separate all the required data collected on the text file by a ','\n",
    "      actorId = columns[1].find('a').get('href')\n",
    "      actorId = actorId.replace('.htm','')\n",
    "      actorId = actorId.replace('./chart/?view=Actor&id=','')\n",
    "#condition to put the actors ID in the 2nd column\n",
    "      numOfMovies = columns[3].get_text()\n",
    "      num1Picture = columns[5].get_text()\n",
    "      totalGross = removeChar(',',columns[2].get_text())\n",
    "\n",
    "      strAvgEarnPerMovie = columns[4].get_text()\n",
    "\n",
    "      strAvgEarnPerMovie = strAvgEarnPerMovie.replace('$','')\n",
    "      strAvgEarnPerMovie = strAvgEarnPerMovie.replace('k','')\n",
    "\n",
    "      avgEarnPerMovie = float(strAvgEarnPerMovie)\n",
    "\n",
    "      if int(numOfMovies) > globalMaxMovieCount:\n",
    "        globalActorsWithMaxMovies = actorName\n",
    "        globalMaxMovieCount = int(numOfMovies)\n",
    "      elif numOfMovies == globalMaxMovieCount:\n",
    "        globalActorsWithMaxMovies += \", \"+ actorName\n",
    "\n",
    "      if avgEarnPerMovie > globalMaxAvgEarnMovie:\n",
    "        globalActorsWithMaxAvgPerMovie = actorName\n",
    "        globalMaxAvgEarnMovie = avgEarnPerMovie\n",
    "      elif avgEarnPerMovie == globalMaxAvgEarnMovie:\n",
    "        if globalActorsWithMaxAvgPerMovie.find(actorName) == -1:\n",
    "          globalActorsWithMaxAvgPerMovie += \", \"+ actorName\n",
    "\n",
    "      fileToWrite = open(constFileName, \"a\")\n",
    "      fileToWrite.write(str(rowNum) +\",\" + actorName +\",\"+ actorId +\",\" + totalGross +\",\"+ numOfMovies +\",\"+ num1Picture+\"\\n\")\n",
    "\n",
    "    currentRowIndex += 1\n",
    "#condition of the order of the data of an actor to be written in the .text file\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "baseYearUrlToOpen = urlopen(actorsHomeURL)\n",
    "readSource = BeautifulSoup(baseYearUrlToOpen.read())\n",
    "#using beautifulsoup to read the web page of actors information\n",
    "allPageList = []\n",
    "allPageSet = []\n",
    "#using append to add data at the end of the list\n",
    "allLinks = readSource.findAll('a')\n",
    "for hrefTag in allLinks:\n",
    "  if str(hrefTag.get('href')).find(constPageHrefIncluded) != -1:\n",
    "    allPageList.append(urlBoxOfficeMojoHome + str(hrefTag.get('href')))\n",
    "\n",
    "allPageList.append(actorsHomeURL)\n",
    "\n",
    "allPageSet = set(allPageList)\n",
    "\n",
    "sortedPageList = []\n",
    "pageCount = len(allPageSet) + 1\n",
    "pageIndex = 1\n",
    "\n",
    "while pageIndex <= pageCount:\n",
    "  sortedPageList.append(urlPre + str(pageIndex) + urlPost)\n",
    "  pageIndex += 1\n",
    "\n",
    "if os.path.exists(constFileName):\n",
    "  os.remove(constFileName)\n",
    "\n",
    "globalActorsWithMaxMovies = ''\n",
    "globalMaxMovieCount = 0\n",
    "globalMaxAvgEarnMovie = 0.0\n",
    "globalActorsWithMaxAvgPerMovie = ''\n",
    "globalRowIndex = 0\n",
    "\n",
    "for l_currentPage in sortedPageList:\n",
    "  writeActorDataTable(l_currentPage)\n",
    "print(constActorsDataSotred)\n",
    "\n",
    "print(\"The actor(s) with the maximum number of movies is: \"+ globalActorsWithMaxMovies);\n",
    "print(\"The actor(s) with the highest average earnings per movie is: \"+ globalActorsWithMaxAvgPerMovie)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
